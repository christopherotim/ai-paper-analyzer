# ğŸ—ï¸ AI è®ºæ–‡æ™ºèƒ½åˆ†æç³»ç»Ÿ - æŠ€æœ¯æ¶æ„è®¾è®¡

<div align="center">

[English](./ARCHITECTURE.en.md) | [ç®€ä½“ä¸­æ–‡](./ARCHITECTURE.md)

</div>

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [æ•´ä½“æ¶æ„](#æ•´ä½“æ¶æ„)
- [æ ¸å¿ƒæ¨¡å—è®¾è®¡](#æ ¸å¿ƒæ¨¡å—è®¾è®¡)
- [æ•°æ®æµè®¾è®¡](#æ•°æ®æµè®¾è®¡)
- [æŠ€æœ¯æ ˆé€‰å‹](#æŠ€æœ¯æ ˆé€‰å‹)
- [éƒ¨ç½²æ¶æ„](#éƒ¨ç½²æ¶æ„)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [å®‰å…¨è®¾è®¡](#å®‰å…¨è®¾è®¡)
- [æ‰©å±•æ€§è®¾è®¡](#æ‰©å±•æ€§è®¾è®¡)

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

### ç³»ç»Ÿå®šä½

AI è®ºæ–‡æ™ºèƒ½åˆ†æç³»ç»Ÿæ˜¯ä¸€ä¸ªé¢å‘ç ”ç©¶äººå‘˜ã€äº§å“ç»ç†ã€å¼€å‘è€…å’Œå­¦è€…çš„æ™ºèƒ½åŒ–è®ºæ–‡å¤„ç†å·¥å…·ï¼Œé€šè¿‡é›†æˆå¤šç§ AI æ¨¡å‹ï¼Œå®ç°è®ºæ–‡çš„è‡ªåŠ¨è·å–ã€åˆ†æã€åˆ†ç±»å’ŒæŠ¥å‘Šç”Ÿæˆã€‚

### æ ¸å¿ƒä»·å€¼

- **è‡ªåŠ¨åŒ–**ï¼šå‡å°‘æ‰‹åŠ¨ç­›é€‰è®ºæ–‡çš„å·¥ä½œé‡
- **æ™ºèƒ½åŒ–**ï¼šAI é©±åŠ¨çš„å†…å®¹åˆ†æå’Œåˆ†ç±»
- **æ ‡å‡†åŒ–**ï¼šç»Ÿä¸€çš„åˆ†ææŠ¥å‘Šæ ¼å¼
- **é«˜æ•ˆæ€§**ï¼šæ‰¹é‡å¤„ç†å’Œå¢é‡æ›´æ–°

### ç³»ç»Ÿè¾¹ç•Œ

```
è¾“å…¥ï¼šHuggingFaceè®ºæ–‡æ•°æ®ã€ç”¨æˆ·é…ç½®
å¤„ç†ï¼šæ•°æ®æ¸…æ´—ã€AIåˆ†æã€æ™ºèƒ½åˆ†ç±»
è¾“å‡ºï¼šç»“æ„åŒ–æŠ¥å‘Šã€åˆ†ç±»æ–‡ä»¶ã€ç»Ÿè®¡æ•°æ®
```

## ğŸ›ï¸ æ•´ä½“æ¶æ„

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·æ¥å£å±‚ (UI Layer)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   GUI Interface    â”‚         CLI Interface                 â”‚
â”‚   (Tkinter)        â”‚         (Argparse)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ä¸šåŠ¡é€»è¾‘å±‚ (Business Layer)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Main Controller  â”‚   Batch Processorâ”‚   Report Generator   â”‚
â”‚   (main.py)        â”‚   (batch_*.py)   â”‚   (report.py)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æ ¸å¿ƒæœåŠ¡å±‚ (Core Layer)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Fetcherâ”‚  Analyzer   â”‚ Classifier  â”‚   Parser         â”‚
â”‚  (fetcher.py)â”‚(analyzer.py)â”‚(classifier.py)â”‚ (parser.py)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   åŸºç¡€è®¾æ–½å±‚ (Infrastructure Layer)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AI Clients  â”‚File Manager â”‚   Logger    â”‚   Config Manager â”‚
â”‚(ai_client.py)â”‚(file_utils.py)â”‚(logger.py)â”‚  (config.py)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æ•°æ®å­˜å‚¨å±‚ (Data Layer)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Metadata  â”‚   Cleaned   â”‚   Reports   â”‚   Analysis       â”‚
â”‚   (JSON)    â”‚   (JSON)    â”‚   (JSON)    â”‚   (Markdown)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¶æ„ç‰¹ç‚¹

1. **åˆ†å±‚æ¶æ„**ï¼šæ¸…æ™°çš„èŒè´£åˆ†ç¦»ï¼Œä¾¿äºç»´æŠ¤å’Œæµ‹è¯•
2. **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€ï¼Œé«˜å†…èšä½è€¦åˆ
3. **æ’ä»¶åŒ– AI**ï¼šæ”¯æŒå¤šç§ AI æ¨¡å‹çš„çƒ­æ’æ‹”
4. **æ•°æ®é©±åŠ¨**ï¼šåŸºäºé…ç½®æ–‡ä»¶çš„çµæ´»é…ç½®

## ğŸ§© æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 1. æ•°æ®è·å–æ¨¡å— (Data Fetcher)

**èŒè´£**ï¼šä» HuggingFace è·å–è®ºæ–‡å…ƒæ•°æ®

**æ ¸å¿ƒç±»**ï¼š

```python
class HuggingFaceFetcher:
    def fetch_daily_papers(self, date: str) -> List[Paper]
    def fetch_paper_details(self, paper_id: str) -> PaperDetail
    def validate_paper_data(self, data: dict) -> bool
```

**è®¾è®¡è¦ç‚¹**ï¼š

- æ”¯æŒå¢é‡è·å–ï¼Œé¿å…é‡å¤ä¸‹è½½
- ç½‘ç»œå¼‚å¸¸é‡è¯•æœºåˆ¶
- æ•°æ®éªŒè¯å’Œæ¸…æ´—
- æ”¯æŒä»£ç†å’Œè¶…æ—¶é…ç½®

### 2. æ•°æ®æ¸…æ´—æ¨¡å— (Data Cleaner)

**èŒè´£**ï¼šæ¸…æ´—å’Œæ ‡å‡†åŒ–åŸå§‹è®ºæ–‡æ•°æ®

**æ ¸å¿ƒç±»**ï¼š

```python
class DataCleaner:
    def clean_metadata(self, raw_data: List[dict]) -> List[dict]
    def normalize_fields(self, paper: dict) -> dict
    def filter_invalid_papers(self, papers: List[dict]) -> List[dict]
```

**è®¾è®¡è¦ç‚¹**ï¼š

- å­—æ®µæ ‡å‡†åŒ–å’Œæ ¼å¼ç»Ÿä¸€
- æ— æ•ˆæ•°æ®è¿‡æ»¤
- é‡å¤æ•°æ®å»é™¤
- æ•°æ®è´¨é‡è¯„ä¼°

### 3. AI åˆ†ææ¨¡å— (Analyzer)

**èŒè´£**ï¼šä½¿ç”¨ AI æ¨¡å‹åˆ†æè®ºæ–‡å†…å®¹

**æ ¸å¿ƒç±»**ï¼š

```python
class PaperAnalyzer:
    def analyze_batch(self, papers: List[Paper]) -> List[AnalysisResult]
    def analyze_single(self, paper: Paper) -> AnalysisResult
    def _build_analysis_prompt(self, paper: Paper) -> str
```

**è®¾è®¡è¦ç‚¹**ï¼š

- å¤š AI æ¨¡å‹æ”¯æŒï¼ˆç­–ç•¥æ¨¡å¼ï¼‰
- æ‰¹é‡å¤„ç†ä¼˜åŒ–
- é”™è¯¯é‡è¯•å’Œé™çº§
- ç»“æœç¼“å­˜æœºåˆ¶

### 4. æ™ºèƒ½åˆ†ç±»æ¨¡å— (Classifier)

**èŒè´£**ï¼šå¯¹åˆ†æç»“æœè¿›è¡Œæ™ºèƒ½åˆ†ç±»

**æ ¸å¿ƒç±»**ï¼š

```python
class PaperClassifier:
    def classify_papers(self, results: List[AnalysisResult]) -> List[ClassificationResult]
    def classify_single_paper(self, result: AnalysisResult) -> ClassificationResult
    def save_classification_results(self, results: List[ClassificationResult]) -> bool
```

**è®¾è®¡è¦ç‚¹**ï¼š

- åŸºäº AI çš„æ™ºèƒ½åˆ†ç±»
- å¯é…ç½®çš„åˆ†ç±»ä½“ç³»
- åˆ†ç±»ç½®ä¿¡åº¦è¯„ä¼°
- åˆ†ç±»ç»“æœå¯è§†åŒ–

### 5. AI å®¢æˆ·ç«¯æ¨¡å— (AI Client)

**èŒè´£**ï¼šç»Ÿä¸€çš„ AI æœåŠ¡æ¥å£

**æ ¸å¿ƒæ¥å£**ï¼š

```python
class AIClient(ABC):
    @abstractmethod
    def chat(self, messages: List[dict]) -> str

    @abstractmethod
    def test_connection(self) -> bool
```

**å®ç°ç±»**ï¼š

- `ZhipuAIClient`ï¼šæ™ºè°± AI å®¢æˆ·ç«¯
- `DoubaoAIClient`ï¼šè±†åŒ… AI å®¢æˆ·ç«¯
- `OpenAIClient`ï¼šOpenAI å®¢æˆ·ç«¯
- `QwenAIClient`ï¼šé€šä¹‰åƒé—®å®¢æˆ·ç«¯

**è®¾è®¡è¦ç‚¹**ï¼š

- ç»Ÿä¸€æ¥å£ï¼Œä¾¿äºåˆ‡æ¢
- é‡è¯•å’Œé™æµæœºåˆ¶
- é”™è¯¯å¤„ç†å’Œæ—¥å¿—
- é…ç½®åŒ–å‚æ•°ç®¡ç†

## ğŸ”„ æ•°æ®æµè®¾è®¡

### ä¸»è¦æ•°æ®æµ

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥] --> B[æ•°æ®è·å–]
    B --> C[æ•°æ®æ¸…æ´—]
    C --> D[AIåˆ†æ]
    D --> E[æ™ºèƒ½åˆ†ç±»]
    E --> F[æŠ¥å‘Šç”Ÿæˆ]
    F --> G[ç»“æœè¾“å‡º]

    B --> H[å…ƒæ•°æ®å­˜å‚¨]
    C --> I[æ¸…æ´—æ•°æ®å­˜å‚¨]
    D --> J[åˆ†æç»“æœå­˜å‚¨]
    E --> K[åˆ†ç±»ç»“æœå­˜å‚¨]
    F --> L[æŠ¥å‘Šæ–‡ä»¶å­˜å‚¨]
```

### æ•°æ®æ¨¡å‹è®¾è®¡

**Paper æ¨¡å‹**ï¼š

```python
@dataclass
class Paper:
    id: str
    title: str
    translation: str
    authors: str
    url: str
    abstract: str
    created_at: datetime
```

**AnalysisResult æ¨¡å‹**ï¼š

```python
@dataclass
class AnalysisResult:
    paper_id: str
    paper_url: str
    title: str
    translation: str
    authors: str
    publish_date: str
    model_function: str
    page_content: str
    analysis_time: str
```

**ClassificationResult æ¨¡å‹**ï¼š

```python
@dataclass
class ClassificationResult:
    paper_id: str
    category: str
    confidence: float
    md_content: str
    classification_time: str
```

### å­˜å‚¨ç»“æ„è®¾è®¡

```
data/
â”œâ”€â”€ daily_reports/              # åŸºç¡€åˆ†ææ•°æ®
â”‚   â”œâ”€â”€ metadata/              # åŸå§‹å…ƒæ•°æ®
â”‚   â”‚   â””â”€â”€ YYYY-MM-DD.json
â”‚   â”œâ”€â”€ cleaned/               # æ¸…æ´—åæ•°æ®
â”‚   â”‚   â””â”€â”€ YYYY-MM-DD.json
â”‚   â””â”€â”€ reports/               # åˆ†ææŠ¥å‘Š
â”‚       â””â”€â”€ YYYY-MM-DD_report.json
â”œâ”€â”€ analysis_results/          # åˆ†ç±»åˆ†æç»“æœ
â”‚   â””â”€â”€ YYYY-MM-DD/
â”‚       â”œâ”€â”€ æ–‡æœ¬ç”Ÿæˆ/
â”‚       â”œâ”€â”€ å›¾åƒç”Ÿæˆ/
â”‚       â”œâ”€â”€ è§†é¢‘ç”Ÿæˆ/
â”‚       â””â”€â”€ classification_stats.json
â””â”€â”€ logs/                      # ç³»ç»Ÿæ—¥å¿—
    â”œâ”€â”€ app.log
    â”œâ”€â”€ error.log
    â””â”€â”€ performance.log
```

## ğŸ› ï¸ æŠ€æœ¯æ ˆé€‰å‹

### ç¼–ç¨‹è¯­è¨€

- **Python 3.8+**ï¼šä¸»è¦å¼€å‘è¯­è¨€
  - ä¸°å¯Œçš„ AI/ML ç”Ÿæ€
  - ä¼˜ç§€çš„å¼‚æ­¥æ”¯æŒ
  - è·¨å¹³å°å…¼å®¹æ€§

### æ ¸å¿ƒä¾èµ–

**AI æœåŠ¡é›†æˆ**ï¼š

```python
# AIæ¨¡å‹å®¢æˆ·ç«¯
zhipuai>=2.0.0          # æ™ºè°±AI
openai>=1.0.0           # OpenAI
dashscope>=1.0.0        # é€šä¹‰åƒé—®
volcengine>=1.0.0       # è±†åŒ…AI
```

**GUI æ¡†æ¶**ï¼š

```python
tkinter                 # å†…ç½®GUIæ¡†æ¶
tkcalendar>=1.6.0      # æ—¥æœŸé€‰æ‹©å™¨
```

**æ•°æ®å¤„ç†**ï¼š

```python
requests>=2.28.0       # HTTPå®¢æˆ·ç«¯
beautifulsoup4>=4.11.0 # HTMLè§£æ
pandas>=1.5.0          # æ•°æ®å¤„ç†
```

**ç³»ç»Ÿå·¥å…·**ï¼š

```python
pyyaml>=6.0            # é…ç½®æ–‡ä»¶è§£æ
colorama>=0.4.0        # ç»ˆç«¯é¢œè‰²
rich>=12.0.0           # å¯Œæ–‡æœ¬æ˜¾ç¤º
```

### æ¶æ„æ¨¡å¼

**è®¾è®¡æ¨¡å¼åº”ç”¨**ï¼š

1. **ç­–ç•¥æ¨¡å¼**ï¼šAI å®¢æˆ·ç«¯çš„å¤šå®ç°
2. **å·¥å‚æ¨¡å¼**ï¼šAI å®¢æˆ·ç«¯åˆ›å»º
3. **è§‚å¯Ÿè€…æ¨¡å¼**ï¼šè¿›åº¦é€šçŸ¥
4. **å•ä¾‹æ¨¡å¼**ï¼šé…ç½®ç®¡ç†
5. **æ¨¡æ¿æ–¹æ³•**ï¼šæ•°æ®å¤„ç†æµç¨‹

**å¼‚æ­¥ç¼–ç¨‹**ï¼š

```python
# å¼‚æ­¥æ•°æ®è·å–
async def fetch_papers_async(dates: List[str]) -> List[Paper]:
    tasks = [fetch_single_date(date) for date in dates]
    results = await asyncio.gather(*tasks)
    return flatten(results)
```

## ğŸš€ éƒ¨ç½²æ¶æ„

### æœ¬åœ°éƒ¨ç½²

**ç³»ç»Ÿè¦æ±‚**ï¼š

```yaml
minimum:
  python: "3.8+"
  memory: "4GB"
  storage: "2GB"
  network: "stable internet"

recommended:
  python: "3.10+"
  memory: "8GB+"
  storage: "10GB+"
  network: "high-speed internet"
```

**éƒ¨ç½²æ­¥éª¤**ï¼š

```bash
# 1. ç¯å¢ƒå‡†å¤‡
git clone https://github.com/ZsTs119/ai-paper-analyzer.git
cd ai-paper-analyzer
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 2. ä¾èµ–å®‰è£…
pip install -r requirements.txt

# 3. é…ç½®è®¾ç½®
cp config/app.yaml.example config/app.yaml
# ç¼–è¾‘é…ç½®æ–‡ä»¶

# 4. å¯åŠ¨åº”ç”¨
python run_gui.py  # GUIç‰ˆæœ¬
python run.py basic  # CLIç‰ˆæœ¬
```

### Docker éƒ¨ç½²

**Dockerfile**ï¼š

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    git \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºæ•°æ®ç›®å½•
RUN mkdir -p data logs

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV PYTHONIOENCODING=utf-8

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœæœ‰Webç•Œé¢ï¼‰
EXPOSE 8080

# å¯åŠ¨å‘½ä»¤
CMD ["python", "run.py", "basic"]
```

**docker-compose.yml**ï¼š

```yaml
version: "3.8"

services:
  ai-paper-analyzer:
    build: .
    container_name: paper-analyzer
    environment:
      - ZHIPUAI_API_KEY=${ZHIPUAI_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config:/app/config
    restart: unless-stopped
```

### äº‘éƒ¨ç½²

**æ”¯æŒçš„äº‘å¹³å°**ï¼š

1. **AWS EC2**ï¼šå¼¹æ€§è®¡ç®—å®ä¾‹
2. **Google Cloud Compute**ï¼šè™šæ‹Ÿæœºå®ä¾‹
3. **Azure VM**ï¼šè™šæ‹ŸæœºæœåŠ¡
4. **é˜¿é‡Œäº‘ ECS**ï¼šå¼¹æ€§è®¡ç®—æœåŠ¡

**äº‘éƒ¨ç½²ä¼˜åŠ¿**ï¼š

- å¼¹æ€§æ‰©ç¼©å®¹
- é«˜å¯ç”¨æ€§
- è‡ªåŠ¨å¤‡ä»½
- ç›‘æ§å‘Šè­¦

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å¹¶å‘å¤„ç†

**å¼‚æ­¥ IO ä¼˜åŒ–**ï¼š

```python
class AsyncPaperProcessor:
    def __init__(self, max_concurrent: int = 10):
        self.semaphore = asyncio.Semaphore(max_concurrent)

    async def process_papers_batch(self, papers: List[Paper]) -> List[AnalysisResult]:
        tasks = []
        for paper in papers:
            task = self._process_single_paper(paper)
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)
        return [r for r in results if not isinstance(r, Exception)]

    async def _process_single_paper(self, paper: Paper) -> AnalysisResult:
        async with self.semaphore:
            return await self.analyzer.analyze_async(paper)
```

**æ‰¹é‡å¤„ç†ä¼˜åŒ–**ï¼š

```python
class BatchOptimizer:
    def __init__(self, batch_size: int = 10):
        self.batch_size = batch_size

    def optimize_batch_size(self, total_items: int, api_limit: int) -> int:
        """åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°"""
        optimal_size = min(self.batch_size, api_limit, total_items)
        return max(1, optimal_size)
```

### ç¼“å­˜ç­–ç•¥

**å¤šçº§ç¼“å­˜**ï¼š

```python
class CacheManager:
    def __init__(self):
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜
        self.disk_cache_dir = Path("cache")  # ç£ç›˜ç¼“å­˜

    def get_analysis_result(self, paper_id: str) -> Optional[AnalysisResult]:
        # 1. æ£€æŸ¥å†…å­˜ç¼“å­˜
        if paper_id in self.memory_cache:
            return self.memory_cache[paper_id]

        # 2. æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cache_file = self.disk_cache_dir / f"{paper_id}.json"
        if cache_file.exists():
            result = self._load_from_disk(cache_file)
            self.memory_cache[paper_id] = result  # åŠ è½½åˆ°å†…å­˜
            return result

        return None
```

### èµ„æºç®¡ç†

**å†…å­˜ä¼˜åŒ–**ï¼š

```python
class MemoryManager:
    def __init__(self, max_memory_mb: int = 500):
        self.max_memory = max_memory_mb * 1024 * 1024

    def check_memory_usage(self):
        """ç›‘æ§å†…å­˜ä½¿ç”¨"""
        import psutil
        process = psutil.Process()
        memory_usage = process.memory_info().rss

        if memory_usage > self.max_memory:
            self._cleanup_cache()

    def _cleanup_cache(self):
        """æ¸…ç†ç¼“å­˜é‡Šæ”¾å†…å­˜"""
        # æ¸…ç†æœ€ä¹…æœªä½¿ç”¨çš„ç¼“å­˜é¡¹
        pass
```

**è¿æ¥æ± ç®¡ç†**ï¼š

```python
class ConnectionPoolManager:
    def __init__(self, max_connections: int = 10):
        self.session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=max_connections,
            pool_maxsize=max_connections,
            max_retries=3
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
```

## ğŸ”’ å®‰å…¨è®¾è®¡

### API å¯†é’¥ç®¡ç†

**å®‰å…¨å­˜å‚¨**ï¼š

```python
class SecureKeyManager:
    def __init__(self):
        self.key_file = Path.home() / ".ai_paper_analyzer" / "keys.enc"

    def store_key(self, service: str, api_key: str):
        """åŠ å¯†å­˜å‚¨APIå¯†é’¥"""
        encrypted_key = self._encrypt(api_key)
        self._save_encrypted_key(service, encrypted_key)

    def get_key(self, service: str) -> Optional[str]:
        """è§£å¯†è·å–APIå¯†é’¥"""
        encrypted_key = self._load_encrypted_key(service)
        if encrypted_key:
            return self._decrypt(encrypted_key)
        return None

    def _encrypt(self, data: str) -> bytes:
        """ä½¿ç”¨Fernetå¯¹ç§°åŠ å¯†"""
        from cryptography.fernet import Fernet
        key = self._get_or_create_key()
        f = Fernet(key)
        return f.encrypt(data.encode())

    def _decrypt(self, encrypted_data: bytes) -> str:
        """è§£å¯†æ•°æ®"""
        from cryptography.fernet import Fernet
        key = self._get_or_create_key()
        f = Fernet(key)
        return f.decrypt(encrypted_data).decode()
```

**ç¯å¢ƒå˜é‡éªŒè¯**ï¼š

```python
class EnvironmentValidator:
    REQUIRED_VARS = {
        'ZHIPUAI_API_KEY': r'^[a-zA-Z0-9\-_\.]+$',
        'OPENAI_API_KEY': r'^sk-[a-zA-Z0-9]+$',
        'DASHSCOPE_API_KEY': r'^sk-[a-zA-Z0-9]+$'
    }

    def validate_api_keys(self) -> Dict[str, bool]:
        """éªŒè¯APIå¯†é’¥æ ¼å¼"""
        results = {}
        for var_name, pattern in self.REQUIRED_VARS.items():
            value = os.getenv(var_name)
            if value:
                results[var_name] = bool(re.match(pattern, value))
            else:
                results[var_name] = False
        return results
```

### æ•°æ®å®‰å…¨

**æ•æ„Ÿæ•°æ®å¤„ç†**ï¼š

```python
class DataSanitizer:
    SENSITIVE_PATTERNS = [
        r'api[_-]?key',
        r'password',
        r'token',
        r'secret'
    ]

    def sanitize_logs(self, log_content: str) -> str:
        """æ¸…ç†æ—¥å¿—ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
        for pattern in self.SENSITIVE_PATTERNS:
            log_content = re.sub(
                f'{pattern}["\']?[:\s=]+["\']?([^"\s,}}]+)',
                f'{pattern}=***REDACTED***',
                log_content,
                flags=re.IGNORECASE
            )
        return log_content

    def sanitize_config(self, config: dict) -> dict:
        """æ¸…ç†é…ç½®ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
        sanitized = config.copy()
        for key in sanitized:
            if any(pattern in key.lower() for pattern in ['key', 'password', 'token']):
                sanitized[key] = '***REDACTED***'
        return sanitized
```

### ç½‘ç»œå®‰å…¨

**è¯·æ±‚éªŒè¯**ï¼š

```python
class SecureHTTPClient:
    def __init__(self):
        self.session = requests.Session()
        self.session.verify = True  # å¼ºåˆ¶SSLéªŒè¯
        self.session.timeout = 30   # è®¾ç½®è¶…æ—¶

        # è®¾ç½®å®‰å…¨å¤´
        self.session.headers.update({
            'User-Agent': 'AI-Paper-Analyzer/1.0',
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        })

    def make_request(self, url: str, **kwargs) -> requests.Response:
        """å®‰å…¨çš„HTTPè¯·æ±‚"""
        # URLç™½åå•éªŒè¯
        if not self._is_allowed_url(url):
            raise SecurityError(f"URL not in whitelist: {url}")

        # è¯·æ±‚å¤§å°é™åˆ¶
        if 'data' in kwargs and len(str(kwargs['data'])) > 1024 * 1024:  # 1MB
            raise SecurityError("Request payload too large")

        return self.session.request('POST', url, **kwargs)

    def _is_allowed_url(self, url: str) -> bool:
        """æ£€æŸ¥URLæ˜¯å¦åœ¨ç™½åå•ä¸­"""
        allowed_domains = [
            'api.openai.com',
            'open.bigmodel.cn',
            'dashscope.aliyuncs.com',
            'ark.cn-beijing.volces.com',
            'huggingface.co'
        ]
        from urllib.parse import urlparse
        domain = urlparse(url).netloc
        return any(allowed in domain for allowed in allowed_domains)
```

## ğŸ”§ æ‰©å±•æ€§è®¾è®¡

### æ’ä»¶åŒ–æ¶æ„

**AI æ¨¡å‹æ’ä»¶æ¥å£**ï¼š

```python
class AIModelPlugin(ABC):
    """AIæ¨¡å‹æ’ä»¶åŸºç±»"""

    @property
    @abstractmethod
    def name(self) -> str:
        """æ’ä»¶åç§°"""
        pass

    @property
    @abstractmethod
    def version(self) -> str:
        """æ’ä»¶ç‰ˆæœ¬"""
        pass

    @abstractmethod
    def initialize(self, config: dict) -> bool:
        """åˆå§‹åŒ–æ’ä»¶"""
        pass

    @abstractmethod
    def analyze_paper(self, paper: Paper) -> AnalysisResult:
        """åˆ†æè®ºæ–‡"""
        pass

    @abstractmethod
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥"""
        pass

class PluginManager:
    def __init__(self):
        self.plugins: Dict[str, AIModelPlugin] = {}

    def register_plugin(self, plugin: AIModelPlugin):
        """æ³¨å†Œæ’ä»¶"""
        self.plugins[plugin.name] = plugin

    def get_plugin(self, name: str) -> Optional[AIModelPlugin]:
        """è·å–æ’ä»¶"""
        return self.plugins.get(name)

    def list_plugins(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æ’ä»¶"""
        return list(self.plugins.keys())
```

**æ•°æ®æºæ‰©å±•**ï¼š

```python
class DataSourcePlugin(ABC):
    """æ•°æ®æºæ’ä»¶åŸºç±»"""

    @abstractmethod
    def fetch_papers(self, date: str) -> List[Paper]:
        """è·å–è®ºæ–‡æ•°æ®"""
        pass

    @abstractmethod
    def validate_data(self, data: dict) -> bool:
        """éªŒè¯æ•°æ®æ ¼å¼"""
        pass

class ArxivDataSource(DataSourcePlugin):
    """ArXivæ•°æ®æºå®ç°"""

    def fetch_papers(self, date: str) -> List[Paper]:
        # ArXiv APIå®ç°
        pass

class PubMedDataSource(DataSourcePlugin):
    """PubMedæ•°æ®æºå®ç°"""

    def fetch_papers(self, date: str) -> List[Paper]:
        # PubMed APIå®ç°
        pass
```

### é…ç½®åŒ–æ‰©å±•

**åŠ¨æ€é…ç½®åŠ è½½**ï¼š

```python
class ConfigurableSystem:
    def __init__(self, config_dir: str = "config"):
        self.config_dir = Path(config_dir)
        self.watchers = {}

    def load_plugin_configs(self) -> Dict[str, dict]:
        """åŠ è½½æ’ä»¶é…ç½®"""
        configs = {}
        plugin_config_dir = self.config_dir / "plugins"

        if plugin_config_dir.exists():
            for config_file in plugin_config_dir.glob("*.yaml"):
                plugin_name = config_file.stem
                with open(config_file, 'r', encoding='utf-8') as f:
                    configs[plugin_name] = yaml.safe_load(f)

        return configs

    def watch_config_changes(self, callback):
        """ç›‘æ§é…ç½®æ–‡ä»¶å˜åŒ–"""
        from watchdog.observers import Observer
        from watchdog.events import FileSystemEventHandler

        class ConfigHandler(FileSystemEventHandler):
            def on_modified(self, event):
                if event.src_path.endswith('.yaml'):
                    callback(event.src_path)

        observer = Observer()
        observer.schedule(ConfigHandler(), str(self.config_dir), recursive=True)
        observer.start()
        return observer
```

### å¾®æœåŠ¡åŒ–æ”¯æŒ

**æœåŠ¡æ‹†åˆ†è®¾è®¡**ï¼š

```python
# æ•°æ®è·å–æœåŠ¡
class DataFetchService:
    def __init__(self, port: int = 8001):
        self.app = FastAPI()
        self.port = port
        self._setup_routes()

    def _setup_routes(self):
        @self.app.post("/fetch/{date}")
        async def fetch_papers(date: str):
            fetcher = HuggingFaceFetcher()
            papers = await fetcher.fetch_daily_papers(date)
            return {"papers": [p.to_dict() for p in papers]}

# AIåˆ†ææœåŠ¡
class AnalysisService:
    def __init__(self, port: int = 8002):
        self.app = FastAPI()
        self.port = port
        self._setup_routes()

    def _setup_routes(self):
        @self.app.post("/analyze")
        async def analyze_papers(papers: List[dict]):
            analyzer = PaperAnalyzer(config)
            results = await analyzer.analyze_batch_async(papers)
            return {"results": [r.to_dict() for r in results]}

# åˆ†ç±»æœåŠ¡
class ClassificationService:
    def __init__(self, port: int = 8003):
        self.app = FastAPI()
        self.port = port
        self._setup_routes()

    def _setup_routes(self):
        @self.app.post("/classify")
        async def classify_papers(analysis_results: List[dict]):
            classifier = PaperClassifier(config)
            results = await classifier.classify_batch_async(analysis_results)
            return {"classifications": [r.to_dict() for r in results]}
```

## ğŸ“Š ç›‘æ§ä¸è¿ç»´

### ç³»ç»Ÿç›‘æ§

**æ€§èƒ½æŒ‡æ ‡æ”¶é›†**ï¼š

```python
class MetricsCollector:
    def __init__(self):
        self.metrics = {
            'papers_processed': 0,
            'analysis_success_rate': 0.0,
            'average_processing_time': 0.0,
            'api_call_count': 0,
            'error_count': 0
        }

    def record_paper_processed(self, processing_time: float, success: bool):
        """è®°å½•è®ºæ–‡å¤„ç†æŒ‡æ ‡"""
        self.metrics['papers_processed'] += 1
        if success:
            self.metrics['analysis_success_rate'] = (
                self.metrics['analysis_success_rate'] * (self.metrics['papers_processed'] - 1) + 1
            ) / self.metrics['papers_processed']

        self.metrics['average_processing_time'] = (
            self.metrics['average_processing_time'] * (self.metrics['papers_processed'] - 1) + processing_time
        ) / self.metrics['papers_processed']

    def export_metrics(self) -> dict:
        """å¯¼å‡ºæŒ‡æ ‡æ•°æ®"""
        return self.metrics.copy()
```

**å¥åº·æ£€æŸ¥**ï¼š

```python
class HealthChecker:
    def __init__(self):
        self.checks = {
            'database': self._check_database,
            'ai_services': self._check_ai_services,
            'disk_space': self._check_disk_space,
            'memory_usage': self._check_memory_usage
        }

    async def run_health_checks(self) -> Dict[str, bool]:
        """è¿è¡Œæ‰€æœ‰å¥åº·æ£€æŸ¥"""
        results = {}
        for check_name, check_func in self.checks.items():
            try:
                results[check_name] = await check_func()
            except Exception as e:
                logger.error(f"Health check {check_name} failed: {e}")
                results[check_name] = False
        return results

    async def _check_ai_services(self) -> bool:
        """æ£€æŸ¥AIæœåŠ¡å¯ç”¨æ€§"""
        # å®ç°AIæœåŠ¡è¿é€šæ€§æ£€æŸ¥
        pass

    async def _check_disk_space(self) -> bool:
        """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
        import shutil
        total, used, free = shutil.disk_usage(".")
        usage_percent = (used / total) * 100
        return usage_percent < 90  # ç£ç›˜ä½¿ç”¨ç‡å°äº90%
```

## ğŸ¯ æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

1. **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¸…æ™°çš„åˆ†å±‚æ¶æ„ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•
2. **å¤š AI æ”¯æŒ**ï¼šæ’ä»¶åŒ–çš„ AI æ¨¡å‹é›†æˆæ–¹æ¡ˆ
3. **é«˜æ€§èƒ½**ï¼šå¼‚æ­¥å¤„ç†å’Œå¤šçº§ç¼“å­˜ä¼˜åŒ–
4. **å®‰å…¨å¯é **ï¼šå®Œå–„çš„å®‰å…¨æœºåˆ¶å’Œé”™è¯¯å¤„ç†
5. **æ˜“äºéƒ¨ç½²**ï¼šæ”¯æŒæœ¬åœ°ã€Docker å’Œäº‘éƒ¨ç½²
6. **å¯æ‰©å±•æ€§**ï¼šæ’ä»¶åŒ–æ¶æ„æ”¯æŒåŠŸèƒ½æ‰©å±•

### æŠ€æœ¯ç‰¹è‰²

- åŸºäº Python 3.8+çš„ç°ä»£åŒ–æŠ€æœ¯æ ˆ
- å¼‚æ­¥ç¼–ç¨‹æå‡å¹¶å‘æ€§èƒ½
- å¤šç§è®¾è®¡æ¨¡å¼çš„åˆç†åº”ç”¨
- å®Œå–„çš„ç›‘æ§å’Œè¿ç»´æ”¯æŒ
- å®‰å…¨çš„ API å¯†é’¥ç®¡ç†æœºåˆ¶

### æœªæ¥å‘å±•

- å¾®æœåŠ¡åŒ–æ¶æ„æ¼”è¿›
- æ›´å¤š AI æ¨¡å‹å’Œæ•°æ®æºæ”¯æŒ
- Web ç•Œé¢å’Œ API æœåŠ¡
- åˆ†å¸ƒå¼å¤„ç†èƒ½åŠ›
- æœºå™¨å­¦ä¹ æ¨¡å‹ä¼˜åŒ–
