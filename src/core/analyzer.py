"""
AIåˆ†æå™¨æ¨¡å—
è´Ÿè´£ä½¿ç”¨AIåˆ†æè®ºæ–‡å†…å®¹å¹¶ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦
"""
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any, Optional
from pathlib import Path

from ..utils.console import ConsoleOutput
from ..utils.logger import get_logger
from ..utils.file_utils import FileManager
from ..utils.progress import ProgressManager
from ..utils.ai_client import create_retryable_client
from ..models.paper import Paper
from ..models.report import AnalysisResult, DailyReport
from .parser import ContentParser


class PaperAnalyzer:
    """
    è®ºæ–‡AIåˆ†æå™¨
    
    è´Ÿè´£ä½¿ç”¨AIåˆ†æè®ºæ–‡å†…å®¹ï¼Œç”Ÿæˆç»“æ„åŒ–çš„åˆ†æç»“æœ
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.console = ConsoleOutput()
        self.logger = get_logger('analyzer')
        self.file_manager = FileManager('analyzer')
        self.parser = ContentParser()
        
        # è®¾ç½®é»˜è®¤é…ç½®
        self.output_dir = config.get('output_dir', 'data/daily_reports')
        self.ai_model = config.get('ai_model', 'zhipu')
        self.use_ai = config.get('use_ai', True)
        self.max_retries = config.get('max_retries', 3)
        self.retry_delay = config.get('retry_delay', 2)
        
        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        self.ai_client = None
        if self.use_ai:
            try:
                self.ai_client = create_retryable_client(
                    self.ai_model,
                    max_retries=self.max_retries
                )
            except Exception as e:
                self.logger.warning(f"AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.use_ai = False
    
    def analyze_batch(self, papers: List[Paper], date: str = None, silent: bool = False) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æè®ºæ–‡
        
        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            date: æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆç”¨äºä¿å­˜ç»“æœï¼‰
            silent: æ˜¯å¦é™é»˜æ¨¡å¼
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        if not papers:
            if not silent:
                self.console.print_warning("æ²¡æœ‰è®ºæ–‡éœ€è¦åˆ†æ")
            return []
        
        if not silent:
            self.console.print_header("AIåˆ†æç”Ÿæˆæ‘˜è¦", 3)
            self.console.print_info(f"å¼€å§‹é¡ºåºå¤„ç† {len(papers)} ç¯‡è®ºæ–‡")
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(papers)} ç¯‡è®ºæ–‡")
        
        # åˆå§‹åŒ–è¿›åº¦ç®¡ç†å™¨
        progress = ProgressManager(len(papers), "AIåˆ†æè®ºæ–‡") if not silent else None
        results = []
        
        # å‡†å¤‡è¾“å‡ºæ–‡ä»¶ï¼ˆå¦‚æœæä¾›äº†æ—¥æœŸï¼‰
        final_file = None
        if date:
            final_dir = Path(self.output_dir) / 'reports'
            self.file_manager.ensure_dir(final_dir)
            final_file = final_dir / f"{date}_report.json"
            
            # åŠ è½½å·²å­˜åœ¨çš„ç»“æœ
            existing_results = self._load_existing_results(final_file)
            existing_ids = {self._extract_paper_id_from_result(r) for r in existing_results}
        else:
            existing_ids = set()
        
        # ç»Ÿè®¡å˜é‡
        processed_count = 0
        success_count = 0
        fail_count = 0
        skip_count = 0

        # é¡ºåºå¤„ç†æ¯ç¯‡è®ºæ–‡
        for i, paper in enumerate(papers):
            # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
            if date and paper.id in existing_ids:
                skip_count += 1
                if not silent:
                    self.console.print_skip(f"å·²å¤„ç†çš„è®ºæ–‡: {paper.id}")
                continue

            processed_count += 1

            if not silent:
                # æ˜¾ç¤ºå½“å‰å¤„ç†çš„è®ºæ–‡ä¿¡æ¯
                self.console.print_info(f"ğŸ” å¤„ç†ç¬¬ {i+1}/{len(papers)} é¡¹: {paper.translation}")

                # æ˜¾ç¤ºæ•´ä½“è¿›åº¦æ¡
                progress_bar = self._create_progress_bar(i, len(papers))
                remaining_papers = len(papers) - i - 1
                estimated_remaining = remaining_papers * 15  # å‡è®¾æ¯ç¯‡15ç§’
                print(f"ğŸ“Š è¿›åº¦: {progress_bar} {i}/{len(papers)} (æˆåŠŸ:{success_count}, å¤±è´¥:{fail_count}, è·³è¿‡:{skip_count}) é¢„è®¡å‰©ä½™: {estimated_remaining}ç§’")
            
            self.logger.info(f"å¼€å§‹åˆ†æè®ºæ–‡: {paper.id} - {paper.title}")
            
            try:
                # åˆ†æå•ç¯‡è®ºæ–‡ï¼ˆä¿æŒä¸æ‰¹é‡åˆ†æç›¸åŒçš„é™é»˜çŠ¶æ€ï¼‰
                result = self.analyze_single(paper, silent=silent)
                
                if result:
                    # ç«‹å³ä¿å­˜ç»“æœï¼ˆå¦‚æœæä¾›äº†æ–‡ä»¶è·¯å¾„ï¼‰
                    if final_file:
                        self._save_single_result(result, final_file)

                    results.append(result)
                    success_count += 1

                    if progress:
                        progress.update(True, f"{paper.id}")

                    if not silent:
                        self.console.print_success(f"âœ… å®Œæˆ: {paper.id} ({i+1}/{len(papers)})")

                    self.logger.info(f"è®ºæ–‡åˆ†æå®Œæˆ: {paper.id}")
                else:
                    fail_count += 1

                    if progress:
                        progress.update(False, f"{paper.id}")

                    if not silent:
                        self.console.print_error(f"âŒ å¤±è´¥: {paper.id} ({i+1}/{len(papers)})")

                    self.logger.error(f"è®ºæ–‡åˆ†æå¤±è´¥: {paper.id}")
                    
            except Exception as e:
                fail_count += 1

                if progress:
                    progress.update(False, f"{paper.id} - {e}")

                if not silent:
                    self.console.print_error(f"âŒ å¼‚å¸¸: {paper.id} - {e}")

                self.logger.error(f"è®ºæ–‡åˆ†æå¼‚å¸¸: {paper.id} - {e}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        if progress:
            progress.finish()
        
        if not silent:
            # è®¡ç®—å®é™…å¤„ç†çš„è®ºæ–‡æ•°ï¼ˆæ’é™¤è·³è¿‡çš„ï¼‰
            actually_processed = processed_count

            self.console.print_summary("åˆ†æå®Œæˆç»Ÿè®¡", {
                "æ€»è®ºæ–‡æ•°": len(papers),
                "è·³è¿‡è®ºæ–‡": skip_count,
                "å®é™…å¤„ç†": actually_processed,
                "æˆåŠŸåˆ†æ": success_count,
                "åˆ†æå¤±è´¥": fail_count,
                "æˆåŠŸç‡": f"{success_count/max(actually_processed, 1)*100:.1f}%" if actually_processed > 0 else "0.0%"
            })

        self.logger.info(f"æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸ: {success_count}/{actually_processed}ï¼Œè·³è¿‡: {skip_count}")
        return results
    
    def analyze_single(self, paper: Paper, silent: bool = False) -> Optional[AnalysisResult]:
        """
        åˆ†æå•ç¯‡è®ºæ–‡
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
            silent: æ˜¯å¦é™é»˜æ¨¡å¼
            
        Returns:
            åˆ†æç»“æœï¼Œå¤±è´¥è¿”å›None
        """
        if not self.use_ai or not self.ai_client:
            if not silent:
                self.console.print_warning("AIåˆ†ææœªå¯ç”¨ï¼Œè¿”å›åŸºç¡€ç»“æœ")
            
            # è¿”å›åŸºç¡€ç»“æœ
            return AnalysisResult(
                paper_id=paper.id,
                paper_url=paper.url,
                title=paper.title,
                translation=paper.translation,
                authors="",
                publish_date="",
                model_function="",
                page_content=""
            )
        
        # æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        retry_delay = 2

        for attempt in range(max_retries):
            try:
                if not silent and attempt > 0:
                    self.console.print_info(f"é‡è¯•ç¬¬ {attempt} æ¬¡...")

                # æ„å»ºåˆ†ææç¤ºè¯
                prompt = self._build_analysis_prompt(paper)

                messages = [
                    {
                        "role": "user",
                        "content": [{
                            "type": "text",
                            "text": prompt
                        }]
                    }
                ]

                # è°ƒç”¨AIè¿›è¡Œåˆ†æï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰
                import time
                import threading

                if not silent:
                    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºçº¿ç¨‹
                    progress_stop = threading.Event()
                    progress_thread = threading.Thread(
                        target=self._show_analysis_progress,
                        args=(progress_stop, f"åˆ†æè®ºæ–‡: {paper.translation[:30]}...")
                    )
                    progress_thread.daemon = True
                    progress_thread.start()

                start_time = time.time()

                try:
                    # ä½¿ç”¨çº¿ç¨‹è¶…æ—¶å¤„ç†ï¼ˆWindowså…¼å®¹ï¼‰
                    import concurrent.futures

                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(self.ai_client.chat, messages)
                        try:
                            response = future.result(timeout=90)  # 90ç§’è¶…æ—¶
                        except concurrent.futures.TimeoutError:
                            if not silent:
                                progress_stop.set()
                                progress_thread.join(timeout=1)
                                print()  # æ¢è¡Œ
                            raise TimeoutError(f"AIè°ƒç”¨è¶…æ—¶ï¼ˆ90ç§’ï¼‰")

                except TimeoutError:
                    raise  # é‡æ–°æŠ›å‡ºè¶…æ—¶å¼‚å¸¸
                finally:
                    if not silent:
                        progress_stop.set()
                        progress_thread.join(timeout=1)
                        print()  # æ¢è¡Œ

                end_time = time.time()
                if not silent:
                    self.console.print_info(f"AIå“åº”è€—æ—¶: {end_time - start_time:.2f}ç§’")

                # å¦‚æœæˆåŠŸè·å¾—å“åº”ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                if response:
                    break
                else:
                    if attempt < max_retries - 1:
                        if not silent:
                            self.console.print_warning(f"AIå“åº”ä¸ºç©ºï¼Œ{retry_delay}ç§’åé‡è¯•...")
                        time.sleep(retry_delay)
                        continue
                    else:
                        self.logger.error(f"AIåˆ†æå¤±è´¥ï¼Œæ‰€æœ‰é‡è¯•éƒ½è¿”å›ç©ºå“åº”: {paper.id}")
                        return None

            except Exception as e:
                if attempt < max_retries - 1:
                    if not silent:
                        self.console.print_warning(f"AIè°ƒç”¨å¼‚å¸¸: {e}ï¼Œ{retry_delay}ç§’åé‡è¯•...")
                    self.logger.warning(f"AIè°ƒç”¨å¼‚å¸¸ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {e}")
                    time.sleep(retry_delay)
                    continue
                else:
                    self.logger.error(f"AIåˆ†æå¤±è´¥ï¼Œæ‰€æœ‰é‡è¯•éƒ½å¼‚å¸¸: {paper.id} - {e}")
                    return None

        # å¤„ç†AIå“åº”
        try:
            # è§£æAIå“åº”
            parsed_fields = self.parser.parse_analysis_content(response)

            # åˆ›å»ºåˆ†æç»“æœ
            result = AnalysisResult(
                paper_id=paper.id,
                paper_url=paper.url,
                title=paper.title,
                translation=paper.translation,
                authors=parsed_fields['authors'],
                publish_date=parsed_fields['publish_date'],
                model_function=parsed_fields['model_function'],
                page_content=response
            )

            return result

        except Exception as e:
            self.logger.error(f"è§£æAIå“åº”å¼‚å¸¸: {paper.id} - {e}")
            return None
    
    def _build_analysis_prompt(self, paper: Paper) -> str:
        """
        æ„å»ºAIåˆ†ææç¤ºè¯
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
            
        Returns:
            æç¤ºè¯å­—ç¬¦ä¸²
        """
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªAIè®ºæ–‡åˆ†æä¸“å®¶ã€‚è¯·è®¿é—®ä»¥ä¸‹arXivè®ºæ–‡é“¾æ¥ï¼Œä»”ç»†é˜…è¯»è®ºæ–‡å†…å®¹ï¼Œç„¶åä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚

## ä¿¡æ¯è·å–ç­–ç•¥ï¼š
1. å¿…é¡»è®¿é—®arXivé“¾æ¥è·å–å®Œæ•´è®ºæ–‡ä¿¡æ¯
2. åŸºäºè®ºæ–‡å®é™…å†…å®¹è¿›è¡Œåˆ†æï¼Œä¸ä½¿ç”¨å ä½ç¬¦
3. ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰å‡†ç¡®ã€å®Œæ•´çš„å†…å®¹

## è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
**ä½œè€…å›¢é˜Ÿ**ï¼š[è®ºæ–‡ä½œè€…å§“åæˆ–æ‰€å±æœºæ„å›¢é˜Ÿ]
**å‘è¡¨æ—¥æœŸ**ï¼š[è®ºæ–‡çš„å‘è¡¨æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD]
**æ¨¡å‹åŠŸèƒ½**ï¼š[æ¨¡å‹çš„ä¸»è¦åŠŸèƒ½å’Œç”¨é€”ï¼Œ50å­—ä»¥å†…]

## æ³¨æ„äº‹é¡¹ï¼š
- å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œæ¯è¡Œä»¥å¯¹åº”æ ‡ç­¾å¼€å¤´
- æ¯ä¸ªå­—æ®µåé¢ç›´æ¥è·Ÿå…·ä½“å†…å®¹ï¼Œä¸è¦ä½¿ç”¨æ–¹æ‹¬å·
- åŸºäºè®ºæ–‡å®é™…å†…å®¹å¡«å†™ï¼Œä¸è¦ä½¿ç”¨å ä½ç¬¦æˆ–æ¨¡æ¿
- å¦‚æœæŸé¡¹ä¿¡æ¯åœ¨è®ºæ–‡ä¸­æœªæ˜ç¡®æåŠï¼Œå†™"æœªæ˜ç¡®æåŠ"
- æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å¡«å†™å®Œæ•´ï¼Œä¸èƒ½ç•™ç©º

ã€å¾…åˆ†æçš„è®ºæ–‡ä¿¡æ¯ã€‘ï¼š
è®ºæ–‡é“¾æ¥ï¼š{paper.url}
è®ºæ–‡æ ‡é¢˜ï¼š{paper.title}
ä¸­æ–‡æ ‡é¢˜ï¼š{paper.translation}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚ï¼Œè®¿é—®è®ºæ–‡é“¾æ¥å¹¶ç¡®ä¿è¾“å‡ºçš„æ‰€æœ‰å­—æ®µéƒ½æœ‰å®Œæ•´ã€å‡†ç¡®çš„å†…å®¹ã€‚"""
        
        return prompt

    def _show_analysis_progress(self, stop_event, task_name):
        """
        æ˜¾ç¤ºAIåˆ†æè¿›åº¦åŠ¨ç”»

        Args:
            stop_event: åœæ­¢äº‹ä»¶
            task_name: ä»»åŠ¡åç§°
        """
        import sys
        import time

        spinner = ['â ‹', 'â ™', 'â ¹', 'â ¸', 'â ¼', 'â ´', 'â ¦', 'â §', 'â ‡', 'â ']
        start_time = time.time()
        i = 0
        warning_shown = False

        while not stop_event.is_set():
            elapsed = int(time.time() - start_time)
            minutes, seconds = divmod(elapsed, 60)
            time_str = f"{minutes:02d}:{seconds:02d}"

            # åœ¨75ç§’æ—¶æ˜¾ç¤ºè­¦å‘Š
            if elapsed >= 75 and not warning_shown:
                sys.stdout.write(f'\rğŸ§  {task_name} {spinner[i % len(spinner)]} å·²è€—æ—¶: {time_str} âš ï¸ å“åº”è¾ƒæ…¢...')
                warning_shown = True
            else:
                sys.stdout.write(f'\rğŸ§  {task_name} {spinner[i % len(spinner)]} å·²è€—æ—¶: {time_str}')

            sys.stdout.flush()

            time.sleep(0.1)
            i += 1

    def _create_progress_bar(self, current, total, width=50):
        """
        åˆ›å»ºè¿›åº¦æ¡

        Args:
            current: å½“å‰è¿›åº¦
            total: æ€»æ•°
            width: è¿›åº¦æ¡å®½åº¦

        Returns:
            è¿›åº¦æ¡å­—ç¬¦ä¸²
        """
        if total == 0:
            return "[" + "â–‘" * width + "]"

        progress = current / total
        filled = int(width * progress)
        bar = "â–ˆ" * filled + "â–‘" * (width - filled)
        return f"[{bar}]"
    
    def _load_existing_results(self, file_path: Path) -> List[Dict[str, Any]]:
        """
        åŠ è½½å·²å­˜åœ¨çš„ç»“æœæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            å·²å­˜åœ¨çš„ç»“æœåˆ—è¡¨
        """
        if file_path.exists():
            try:
                data = self.file_manager.load_json(file_path)
                return data if isinstance(data, list) else []
            except Exception as e:
                self.logger.error(f"åŠ è½½å·²å­˜åœ¨ç»“æœå¤±è´¥: {e}")
                return []
        return []
    
    def _save_single_result(self, result: AnalysisResult, file_path: Path):
        """
        ä¿å­˜å•ä¸ªåˆ†æç»“æœåˆ°æ–‡ä»¶
        
        Args:
            result: åˆ†æç»“æœ
            file_path: æ–‡ä»¶è·¯å¾„
        """
        try:
            # åŠ è½½ç°æœ‰ç»“æœ
            existing_results = self._load_existing_results(file_path)
            
            # ç§»é™¤å·²å­˜åœ¨çš„ç›¸åŒIDè®ºæ–‡
            existing_results = [
                r for r in existing_results 
                if self._extract_paper_id_from_result(r) != result.paper_id
            ]
            
            # æ·»åŠ æ–°ç»“æœ
            existing_results.append(result.to_dict())
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            self.file_manager.save_json(existing_results, file_path)
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜å•ä¸ªç»“æœå¤±è´¥: {e}")
    
    def _extract_paper_id_from_result(self, result: Dict[str, Any]) -> str:
        """
        ä»ç»“æœä¸­æå–è®ºæ–‡ID
        
        Args:
            result: ç»“æœå­—å…¸
            
        Returns:
            è®ºæ–‡ID
        """
        # å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
        for field in ['paper_id', 'id']:
            if field in result:
                return result[field]
        
        # ä»URLä¸­æå–
        url = result.get('paper_url', '')
        if url:
            return url.split('/')[-1]
        
        return ''
    
    def create_daily_report(self, date: str, analysis_results: List[AnalysisResult]) -> DailyReport:
        """
        åˆ›å»ºæ—¥æŠ¥
        
        Args:
            date: æ—¥æœŸå­—ç¬¦ä¸²
            analysis_results: åˆ†æç»“æœåˆ—è¡¨
            
        Returns:
            æ—¥æŠ¥å¯¹è±¡
        """
        report = DailyReport(
            date=date,
            total_papers=len(analysis_results),
            analysis_results=analysis_results
        )
        
        return report
    
    def save_daily_report(self, report: DailyReport) -> bool:
        """
        ä¿å­˜æ—¥æŠ¥åˆ°æ–‡ä»¶
        
        Args:
            report: æ—¥æŠ¥å¯¹è±¡
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
            reports_dir = Path(self.output_dir) / 'reports'
            self.file_manager.ensure_dir(reports_dir)
            
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            file_path = reports_dir / f"{report.date}_report.json"
            
            # ä¿å­˜æŠ¥å‘Š
            success = report.save_to_file(str(file_path))
            
            if success:
                self.logger.info(f"æ—¥æŠ¥ä¿å­˜æˆåŠŸ: {file_path}")
            else:
                self.logger.error(f"æ—¥æŠ¥ä¿å­˜å¤±è´¥: {file_path}")
            
            return success
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ—¥æŠ¥å¼‚å¸¸: {e}")
            return False
    
    def get_analysis_statistics(self) -> Dict[str, Any]:
        """
        è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        reports_dir = Path(self.output_dir) / 'reports'
        
        if not reports_dir.exists():
            return {"total_reports": 0, "reports": []}
        
        json_files = list(reports_dir.glob("*_report.json"))
        
        return {
            "total_reports": len(json_files),
            "reports": [f.stem for f in json_files],
            "reports_dir": str(reports_dir)
        }


# ä¾¿æ·å‡½æ•°
def create_analyzer(config: Dict[str, Any]) -> PaperAnalyzer:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºåˆ†æå™¨å®ä¾‹
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        PaperAnalyzerå®ä¾‹
    """
    return PaperAnalyzer(config)

def analyze_papers(papers: List[Paper], date: str = None,
                  output_dir: str = 'data/daily_reports',
                  ai_model: str = 'zhipu', silent: bool = False) -> List[AnalysisResult]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æè®ºæ–‡
    
    Args:
        papers: è®ºæ–‡åˆ—è¡¨
        date: æ—¥æœŸå­—ç¬¦ä¸²
        output_dir: è¾“å‡ºç›®å½•
        ai_model: AIæ¨¡å‹ç±»å‹
        silent: æ˜¯å¦é™é»˜æ¨¡å¼
        
    Returns:
        åˆ†æç»“æœåˆ—è¡¨
    """
    config = {
        'output_dir': output_dir,
        'ai_model': ai_model
    }
    analyzer = PaperAnalyzer(config)
    return analyzer.analyze_batch(papers, date, silent)
