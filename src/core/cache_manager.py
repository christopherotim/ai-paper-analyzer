"""
ç¼“å­˜ç®¡ç†å™¨æ¨¡å—
è´Ÿè´£è®ºæ–‡åˆ†æç»“æœçš„ç¼“å­˜ç®¡ç†ï¼Œé¿å…é‡å¤åˆ†æ
"""
import json
import hashlib
import time
from pathlib import Path
from typing import Dict, Any, Optional
from ..models.paper import Paper
from ..models.report import AnalysisResult
from ..utils.logger import get_logger


class PaperCacheManager:
    """
    è®ºæ–‡åˆ†æç¼“å­˜ç®¡ç†å™¨
    
    è´Ÿè´£ç¼“å­˜è®ºæ–‡åˆ†æç»“æœï¼Œé¿å…é‡å¤åˆ†æç›¸åŒè®ºæ–‡
    """
    
    def __init__(self, cache_dir: str = "data/daily_reports/cache"):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.logger = get_logger('cache_manager')
        
        # ç¼“å­˜é…ç½®
        self.cache_expire_days = 30  # ç¼“å­˜è¿‡æœŸå¤©æ•°
        
        self.logger.info(f"ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œç¼“å­˜ç›®å½•: {self.cache_dir}")
    
    def get_cache_key(self, paper: Paper) -> str:
        """
        ç”Ÿæˆè®ºæ–‡çš„ç¼“å­˜é”®
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
            
        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        # ä½¿ç”¨è®ºæ–‡IDã€æ ‡é¢˜å’Œæ‘˜è¦çš„å‰100å­—ç¬¦ç”Ÿæˆå”¯ä¸€é”®
        content = f"{paper.id}_{paper.title}_{paper.summary[:100]}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def get_cached_result(self, paper: Paper) -> Optional[AnalysisResult]:
        """
        è·å–ç¼“å­˜çš„åˆ†æç»“æœ
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
            
        Returns:
            ç¼“å­˜çš„åˆ†æç»“æœï¼Œå¦‚æœä¸å­˜åœ¨æˆ–è¿‡æœŸåˆ™è¿”å›None
        """
        try:
            cache_key = self.get_cache_key(paper)
            cache_file = self.cache_dir / f"{cache_key}.json"
            
            if not cache_file.exists():
                return None
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            if self._is_cache_expired(cache_file):
                self.logger.info(f"ç¼“å­˜å·²è¿‡æœŸï¼Œåˆ é™¤: {cache_file.name}")
                cache_file.unlink()
                return None
            
            # åŠ è½½ç¼“å­˜æ•°æ®
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # è½¬æ¢ä¸ºAnalysisResultå¯¹è±¡
            result = AnalysisResult.from_dict(cache_data['result'])
            
            self.logger.info(f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {paper.id}")
            return result
            
        except Exception as e:
            self.logger.warning(f"è·å–ç¼“å­˜å¤±è´¥: {paper.id} - {e}")
            return None
    
    def save_to_cache(self, paper: Paper, result: AnalysisResult) -> bool:
        """
        ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
            result: åˆ†æç»“æœ
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            cache_key = self.get_cache_key(paper)
            cache_file = self.cache_dir / f"{cache_key}.json"
            
            # æ„å»ºç¼“å­˜æ•°æ®
            cache_data = {
                'paper_id': paper.id,
                'paper_title': paper.title,
                'cache_time': time.time(),
                'result': result.to_dict()
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ğŸ’¾ ç¼“å­˜ä¿å­˜: {paper.id}")
            return True
            
        except Exception as e:
            self.logger.error(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {paper.id} - {e}")
            return False
    
    def _is_cache_expired(self, cache_file: Path) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        
        Args:
            cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦è¿‡æœŸ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            file_mtime = cache_file.stat().st_mtime
            current_time = time.time()
            
            # è®¡ç®—è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            expire_seconds = self.cache_expire_days * 24 * 60 * 60
            
            return (current_time - file_mtime) > expire_seconds
            
        except Exception as e:
            self.logger.warning(f"æ£€æŸ¥ç¼“å­˜è¿‡æœŸå¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶è®¤ä¸ºå·²è¿‡æœŸ
    
    def clear_expired_cache(self) -> int:
        """
        æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶
        
        Returns:
            æ¸…ç†çš„æ–‡ä»¶æ•°é‡
        """
        cleared_count = 0
        
        try:
            for cache_file in self.cache_dir.glob("*.json"):
                if self._is_cache_expired(cache_file):
                    cache_file.unlink()
                    cleared_count += 1
            
            if cleared_count > 0:
                self.logger.info(f"ğŸ§¹ æ¸…ç†è¿‡æœŸç¼“å­˜: {cleared_count} ä¸ªæ–‡ä»¶")
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        
        return cleared_count
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç¼“å­˜ç»Ÿè®¡å­—å…¸
        """
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            total_files = len(cache_files)
            
            # è®¡ç®—ç¼“å­˜å¤§å°
            total_size = sum(f.stat().st_size for f in cache_files)
            size_mb = total_size / (1024 * 1024)
            
            # ç»Ÿè®¡è¿‡æœŸæ–‡ä»¶
            expired_count = sum(1 for f in cache_files if self._is_cache_expired(f))
            
            return {
                "æ€»ç¼“å­˜æ–‡ä»¶": total_files,
                "ç¼“å­˜å¤§å°": f"{size_mb:.2f} MB",
                "è¿‡æœŸæ–‡ä»¶": expired_count,
                "æœ‰æ•ˆæ–‡ä»¶": total_files - expired_count,
                "ç¼“å­˜ç›®å½•": str(self.cache_dir)
            }
            
        except Exception as e:
            self.logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {"é”™è¯¯": str(e)}
    
    def clear_all_cache(self) -> int:
        """
        æ¸…ç†æ‰€æœ‰ç¼“å­˜æ–‡ä»¶
        
        Returns:
            æ¸…ç†çš„æ–‡ä»¶æ•°é‡
        """
        cleared_count = 0
        
        try:
            for cache_file in self.cache_dir.glob("*.json"):
                cache_file.unlink()
                cleared_count += 1
            
            self.logger.info(f"ğŸ§¹ æ¸…ç†æ‰€æœ‰ç¼“å­˜: {cleared_count} ä¸ªæ–‡ä»¶")
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†æ‰€æœ‰ç¼“å­˜å¤±è´¥: {e}")
        
        return cleared_count